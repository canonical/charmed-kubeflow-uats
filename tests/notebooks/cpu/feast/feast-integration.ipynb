{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dabaa482-e436-4948-8986-069c9ed1dd2f",
   "metadata": {},
   "source": [
    "# üß™ User Acceptance Test (UAT) for Feast Integration\n",
    "\n",
    "This notebook performs a full end-to-end User Acceptance Test (UAT) for a Feast setup using PostgreSQL for both the offline and online stores, and a SQL-based registry.\n",
    "\n",
    "## ‚úÖ Steps Covered\n",
    "\n",
    "1. **Load Feast Configuration**  \n",
    "   Loads the `feature_store.yaml` file using the `FEAST_FS_YAML_FILE_PATH` environment variable, enabling dynamic configuration without moving or copying files.\n",
    "\n",
    "2. **Load Sample Data into Offline Store**  \n",
    "   Reads `data/driver_stats.parquet` and loads it into the configured PostgreSQL offline store using credentials from `feature_store.yaml`.\n",
    "\n",
    "3. **Apply Feature Definitions**  \n",
    "   Cleans up the `specs/` directory, ensures it is a valid Python package, and runs `feast apply` to register entities, features, and data sources.\n",
    "\n",
    "4. **Check Registry Structure**  \n",
    "   Connects to the Feast registry database and asserts the presence of all required internal tables.\n",
    "\n",
    "5. **Retrieve Historical Features**  \n",
    "   Fetches historical training data using `get_historical_features()` to verify offline retrieval functionality.\n",
    "\n",
    "6. **Materialize Features to Online Store**  \n",
    "   Uses `materialize()` to load historical features into the online store, validating the materialization pipeline.\n",
    "\n",
    "7. **Verify Online Store Tables**  \n",
    "   Connects to the online PostgreSQL store and checks that feature view tables have been created.\n",
    "\n",
    "8. **Retrieve Online Features**  \n",
    "   Uses `get_online_features()` to ensure real-time retrieval from the online store works with materialized data.\n",
    "\n",
    "---\n",
    "\n",
    "This notebook validates that Feast is correctly configured, connected to both stores, and that offline and online feature retrieval pipelines work end to end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f765c8-dfda-4108-a90d-a51b0579c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please check the requirements.in file for more details\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c1d445-5859-4091-a5ce-ade4c4e6bf79",
   "metadata": {},
   "source": [
    "# Load Feast Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b9ef9-e426-4d59-9c95-a3517c7d64dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from feast import FeatureStore\n",
    "\n",
    "feature_store_yaml_path = os.getenv(\"FEAST_FS_YAML_FILE_PATH\")\n",
    "with open(feature_store_yaml_path, \"r\") as f:\n",
    "    feature_store_file = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33808ad9-e593-4008-92db-d0feb3465fd0",
   "metadata": {},
   "source": [
    "# Load Sample Data into Offline Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15086b96-c3d7-47fd-9e68-4fdf20508d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from data/driver_stats.parquet has been loaded into the 'driver_stats' table in the 'offline_store' database.\n"
     ]
    }
   ],
   "source": [
    "offline_config = feature_store_file.get(\"offline_store\", {})\n",
    "db_user = offline_config.get(\"user\")\n",
    "db_password = offline_config.get(\"password\")\n",
    "db_host = offline_config.get(\"host\")\n",
    "db_port = offline_config.get(\"port\")\n",
    "db_name = offline_config.get(\"database\")\n",
    "\n",
    "if not all([db_user, db_password, db_host, db_port, db_name]):\n",
    "    raise ValueError(\"One or more offline store config values are missing in feature_store.yaml\")\n",
    "\n",
    "parquet_file_path = \"data/driver_stats.parquet\"\n",
    "df = pd.read_parquet(parquet_file_path)\n",
    "\n",
    "engine = create_engine(f\"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\")\n",
    "table_name = \"driver_stats\"\n",
    "df.to_sql(table_name, engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "print(\n",
    "    f\"Data from {parquet_file_path} has been loaded into the '{table_name}' table \"\n",
    "    f\"in the '{db_name}' database.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771d5a5f-9c46-4b38-b6ee-92c7be1cd638",
   "metadata": {},
   "source": [
    "# Apply Feature Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb2a11a7-1bf7-40a2-b870-8b5bb1794fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feast apply executed successfully.\n",
      "\n",
      "No project found in the repository. Using project name feast_project defined in feature_store.yaml\n",
      "Applying changes for project feast_project\n",
      "Deploying infrastructure for driver_hourly_stats2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean up .ipynb_checkpoints to prevent Feast import issues\n",
    "shutil.rmtree(\"specs/.ipynb_checkpoints\", ignore_errors=True)\n",
    "\n",
    "# Ensure 'specs' is recognized as a Python module by Feast\n",
    "with open(\"specs/__init__.py\", \"w\") as f:\n",
    "    f.write(\"\")\n",
    "\n",
    "# Run 'feast apply' from the correct repo directory\n",
    "specs_dir = os.path.join(os.getcwd(), \"specs\")\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\"feast\", \"apply\"], cwd=specs_dir, capture_output=True, text=True, check=True\n",
    "    )\n",
    "    print(\"Feast apply executed successfully.\\n\")\n",
    "    print(result.stdout)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"Error running 'feast apply':\")\n",
    "    print(e.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c89b124-3271-493e-9821-b8f1f4711603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All expected Feast registry tables are present.\n"
     ]
    }
   ],
   "source": [
    "registry_uri = feature_store_file.get(\"registry\", {}).get(\"path\")\n",
    "if not registry_uri:\n",
    "    raise ValueError(\"Registry URI not found in feature_store.yaml\")\n",
    "\n",
    "engine = create_engine(registry_uri)\n",
    "inspector = inspect(engine)\n",
    "existing_tables = set(inspector.get_table_names())\n",
    "\n",
    "expected_tables = {\n",
    "    \"projects\",\n",
    "    \"entities\",\n",
    "    \"data_sources\",\n",
    "    \"feature_views\",\n",
    "    \"stream_feature_views\",\n",
    "    \"on_demand_feature_views\",\n",
    "    \"feature_services\",\n",
    "    \"saved_datasets\",\n",
    "    \"validation_references\",\n",
    "    \"managed_infra\",\n",
    "    \"permissions\",\n",
    "    \"feast_metadata\",\n",
    "}\n",
    "\n",
    "missing_tables = expected_tables - existing_tables\n",
    "assert not missing_tables, f\"Missing tables in registry DB: {missing_tables}\"\n",
    "\n",
    "print(\"‚úÖ All expected Feast registry tables are present.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117a948d-2798-474b-9a19-47e383de330b",
   "metadata": {},
   "source": [
    "# Retrieve Historical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c22fce15-6fb8-4973-9f14-c227c6faa596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/feast/repo_config.py:268: DeprecationWarning: The serialization version 2 and below will be deprecated in the next release. Specifying `entity_key_serialization_version` to 3 is recommended.\n",
      "  warnings.warn(\n",
      "The `path` of the `RegistryConfig` starts with a plain `postgresql` string. We are updating this to `postgresql+psycopg` to ensure that the `psycopg3` driver is used by `sqlalchemy`. If you want to use `psycopg2` pass `postgresql+psycopg2` explicitely to `path`. To silence this warning, pass `postgresql+psycopg` explicitely to `path`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ get_historical_features executed successfully and returned data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_id</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>label_driver_reported_satisfaction</th>\n",
       "      <th>val_to_add</th>\n",
       "      <th>val_to_add_2</th>\n",
       "      <th>conv_rate</th>\n",
       "      <th>acc_rate</th>\n",
       "      <th>avg_daily_trips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>2021-04-12 10:59:42</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.610259</td>\n",
       "      <td>0.319104</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>2021-04-12 08:12:10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.973000</td>\n",
       "      <td>0.305229</td>\n",
       "      <td>822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>2021-04-12 16:40:26</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.585050</td>\n",
       "      <td>0.132386</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   driver_id     event_timestamp  label_driver_reported_satisfaction  \\\n",
       "0       1001 2021-04-12 10:59:42                                   1   \n",
       "1       1002 2021-04-12 08:12:10                                   5   \n",
       "2       1003 2021-04-12 16:40:26                                   3   \n",
       "\n",
       "   val_to_add  val_to_add_2  conv_rate  acc_rate  avg_daily_trips  \n",
       "0           1            10   0.610259  0.319104              564  \n",
       "1           2            20   0.973000  0.305229              822  \n",
       "2           3            30   0.585050  0.132386              650  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "entity_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"driver_id\": [1001, 1002, 1003],\n",
    "        \"event_timestamp\": [\n",
    "            datetime(2021, 4, 12, 10, 59, 42),\n",
    "            datetime(2021, 4, 12, 8, 12, 10),\n",
    "            datetime(2021, 4, 12, 16, 40, 26),\n",
    "        ],\n",
    "        \"label_driver_reported_satisfaction\": [1, 5, 3],\n",
    "        \"val_to_add\": [1, 2, 3],\n",
    "        \"val_to_add_2\": [10, 20, 30],\n",
    "    }\n",
    ")\n",
    "\n",
    "store = FeatureStore(repo_path=\"specs\")\n",
    "\n",
    "try:\n",
    "    df = store.get_historical_features(\n",
    "        entity_df=entity_df,\n",
    "        features=[\n",
    "            \"driver_hourly_stats2:conv_rate\",\n",
    "            \"driver_hourly_stats2:acc_rate\",\n",
    "            \"driver_hourly_stats2:avg_daily_trips\",\n",
    "        ],\n",
    "    ).to_df()\n",
    "\n",
    "    assert not df.empty, \"get_historical_features returned an empty DataFrame\"\n",
    "    print(\"‚úÖ get_historical_features executed successfully and returned data.\")\n",
    "    display(df.head())\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error calling get_historical_features:\")\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c82afb-9198-480c-8038-76c073050cdf",
   "metadata": {},
   "source": [
    "# Materialize Features to Online Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9966ddf-c7c7-496e-b314-3cf2148be508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/feast/repo_config.py:268: DeprecationWarning: The serialization version 2 and below will be deprecated in the next release. Specifying `entity_key_serialization_version` to 3 is recommended.\n",
      "  warnings.warn(\n",
      "The `path` of the `RegistryConfig` starts with a plain `postgresql` string. We are updating this to `postgresql+psycopg` to ensure that the `psycopg3` driver is used by `sqlalchemy`. If you want to use `psycopg2` pass `postgresql+psycopg2` explicitely to `path`. To silence this warning, pass `postgresql+psycopg` explicitely to `path`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Materializing \u001b[1m\u001b[32m1\u001b[0m feature views from \u001b[1m\u001b[32m2021-04-01 00:00:00+00:00\u001b[0m to \u001b[1m\u001b[32m2025-06-06 09:41:46+00:00\u001b[0m into the \u001b[1m\u001b[32mpostgres\u001b[0m online store.\n",
      "\n",
      "\u001b[1m\u001b[32mdriver_hourly_stats2\u001b[0m:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 216.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully materialized features from 2021-04-01 00:00:00 to 2025-06-06 09:41:46.732083.\n"
     ]
    }
   ],
   "source": [
    "store = FeatureStore(repo_path=\"specs\")\n",
    "\n",
    "start = datetime(2021, 4, 1)\n",
    "end = datetime.utcnow()\n",
    "\n",
    "try:\n",
    "    store.materialize(start_date=start, end_date=end)\n",
    "    print(f\"‚úÖ Successfully materialized features from {start} to {end}.\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error during materialization:\")\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1685a27-0ff1-4fad-a8c7-29a54db43a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Table 'feast_project_driver_hourly_stats2' exists in the online store.\n"
     ]
    }
   ],
   "source": [
    "project_name = feature_store_file.get(\"project\")\n",
    "online_config = feature_store_file.get(\"online_store\", {})\n",
    "\n",
    "db_user = online_config.get(\"user\")\n",
    "db_password = online_config.get(\"password\")\n",
    "db_host = online_config.get(\"host\")\n",
    "db_port = online_config.get(\"port\")\n",
    "db_name = online_config.get(\"database\")\n",
    "\n",
    "if not all([db_user, db_password, db_host, db_port, db_name, project_name]):\n",
    "    raise ValueError(\"Missing one or more required config values.\")\n",
    "\n",
    "conn_str = f\"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "inspector = inspect(engine)\n",
    "tables = inspector.get_table_names(schema=\"public\")\n",
    "\n",
    "expected_table = f\"{project_name}_driver_hourly_stats2\"\n",
    "assert expected_table in tables, f\"‚ùå Table '{expected_table}' not found in online store.\"\n",
    "\n",
    "print(f\"‚úÖ Table '{expected_table}' exists in the online store.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e282789-84bf-4d55-a998-40c88cc91044",
   "metadata": {},
   "source": [
    "# Retrieve Online Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e60fe02d-d1f2-46df-8ebf-bb6fd7f314de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/feast/repo_config.py:268: DeprecationWarning: The serialization version 2 and below will be deprecated in the next release. Specifying `entity_key_serialization_version` to 3 is recommended.\n",
      "  warnings.warn(\n",
      "The `path` of the `RegistryConfig` starts with a plain `postgresql` string. We are updating this to `postgresql+psycopg` to ensure that the `psycopg3` driver is used by `sqlalchemy`. If you want to use `psycopg2` pass `postgresql+psycopg2` explicitely to `path`. To silence this warning, pass `postgresql+psycopg` explicitely to `path`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ get_online_features returned non-empty data.\n",
      "{'acc_rate': [0.7248384356498718, 0.2648613750934601],\n",
      " 'avg_daily_trips': [13, 533],\n",
      " 'conv_rate': [0.9506867527961731, 0.8889309167861938],\n",
      " 'driver_id': [1004, 1005]}\n"
     ]
    }
   ],
   "source": [
    "store = FeatureStore(repo_path=\"specs\")  # adjust if needed\n",
    "\n",
    "try:\n",
    "    feature_vector = store.get_online_features(\n",
    "        features=[\n",
    "            \"driver_hourly_stats2:conv_rate\",\n",
    "            \"driver_hourly_stats2:acc_rate\",\n",
    "            \"driver_hourly_stats2:avg_daily_trips\",\n",
    "        ],\n",
    "        entity_rows=[\n",
    "            {\"driver_id\": 1004},\n",
    "            {\"driver_id\": 1005},\n",
    "        ],\n",
    "    ).to_dict()\n",
    "\n",
    "    assert feature_vector and all(\n",
    "        len(v) > 0 for v in feature_vector.values()\n",
    "    ), \"‚ùå No features returned from online store.\"\n",
    "\n",
    "    print(\"‚úÖ get_online_features returned non-empty data.\")\n",
    "    pprint(feature_vector)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error calling get_online_features:\")\n",
    "    print(str(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
